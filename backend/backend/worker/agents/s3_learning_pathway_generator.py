"""
Stage 3: Learning Pathway Generator Agent
Multi-agent learning pathway generation with debate system
"""

import json
import logging
import time
from typing import Dict, List, Optional, Any, Tuple
from pathlib import Path
from pydantic import BaseModel, Field

import dspy
import redis

from backend.shared.models import (
    DocumentAnalysis, ComplexityLevel
)
from backend.shared.utils import get_n_words
from backend.core.config import settings, AGENT_INSTRUCTIONS

logger = logging.getLogger(__name__)

# =============================================================================
# DSPy-Compatible Models (matching debate_course_content_agent structure)
# =============================================================================

class LearningModule(BaseModel):
    """Learning module with documents and objectives"""
    module_id: str
    title: str
    description: str
    documents: List[str]
    learning_objectives: List[str]

class LearningPath(BaseModel):
    """Complete learning path with debate-generated structure"""
    path_id: str
    title: str
    description: str
    target_complexity: ComplexityLevel
    modules: List[LearningModule]

class Stage2Result(BaseModel):
    """Local Stage2Result model for s3 processing"""
    document_analyses: List[DocumentAnalysis] = Field(default_factory=list)
    overview_context: str = ""

class Stage3Result(BaseModel):
    """Local Stage3Result model for s3 processing"""
    stage2_result: Optional[Stage2Result] = None
    learning_paths: List[LearningPath] = Field(default_factory=list)
    target_complexity: Optional[ComplexityLevel] = None
    debate_history: List[str] = Field(default_factory=list)
    additional_instructions: str = ""
    total_modules: int = 0
    metadata: Dict[str, Any] = Field(default_factory=dict)

# =============================================================================
# Configuration
# =============================================================================

class S3Config:
    """Stage 3 Configuration"""
    MAX_DEBATES = settings.MAX_DEBATES
    MIN_MODULES = settings.MIN_MODULES
    MAX_MODULES = settings.MAX_MODULES
    MAX_OVERVIEW_WORDS = settings.MAX_OVERVIEW_WORDS
    MAX_CONTENT_WORDS = settings.MAX_CONTENT_WORDS
    MAX_DOCUMENTS = 30

# =============================================================================
# Utility Functions
# =============================================================================

def prepare_document_info(analyses: List[DocumentAnalysis]) -> str:
    """Prepare comprehensive document information including content"""
    documents_info = []
    
    for doc in analyses[:S3Config.MAX_DOCUMENTS]:
        # Read actual document content
        try:
            with open(doc.file_path, 'r', encoding='utf-8') as f:
                full_content = f.read()
            content_excerpt = get_n_words(full_content, S3Config.MAX_CONTENT_WORDS)
        except Exception as e:
            logger.warning(f"Could not read {doc.file_path}: {e}")
            content_excerpt = f"Content unavailable: {e}"
        
        doc_info = {
            'file_name': Path(doc.file_path).name,
            'file_path': doc.file_path,
            'title': doc.title,
            'doc_type': doc.doc_type.value,
            'complexity_level': doc.complexity_level.value,
            'key_concepts': doc.key_concepts,
            'learning_objectives': doc.learning_objectives,
            'semantic_summary': doc.semantic_summary,
            'prerequisites': doc.prerequisites,
            'related_topics': doc.related_topics,
            'content_excerpt': content_excerpt,
            'code_languages': doc.code_languages
        }
        documents_info.append(doc_info)
    
    return json.dumps(documents_info, indent=2)

def validate_and_complete_learning_path(learning_path: LearningPath, 
                                      document_analyses: List[DocumentAnalysis]) -> LearningPath:
    """Validate and complete a learning path generated by AI"""
    logger.info("🔧 Validating and completing learning path structure")
    
    # Create a mapping of document paths for easy lookup
    doc_paths = [doc.file_path for doc in document_analyses]
    doc_by_path = {doc.file_path: doc for doc in document_analyses}
    
    completed_modules = []
    for i, module in enumerate(learning_path.modules):
        # Ensure module has all required fields
        module_data = {
            'module_id': getattr(module, 'module_id', f"module_{i+1:02d}"),
            'title': module.title,
            'description': module.description,
            'learning_objectives': getattr(module, 'learning_objectives', []),
            'documents': getattr(module, 'documents', [])
        }
        
        # If no documents are assigned, try to assign relevant ones based on content
        if not module_data['documents']:
            # Simple heuristic: assign documents that contain key terms from module title
            title_words = set(module.title.lower().split())
            relevant_docs = []
            
            for doc_path in doc_paths[:3]:  # Limit to first 3 relevant docs
                doc = doc_by_path[doc_path]
                if any(word in doc.title.lower() or word in doc.semantic_summary.lower() 
                       for word in title_words):
                    relevant_docs.append(doc_path)
            
            if not relevant_docs and doc_paths:
                # If no matches, assign the first available document
                relevant_docs = [doc_paths[min(i, len(doc_paths) - 1)]]
            
            module_data['documents'] = relevant_docs
        
        # Create a proper LearningModule object
        completed_module = LearningModule(**module_data)
        completed_modules.append(completed_module)
    
    # Update the learning path with completed modules
    learning_path.modules = completed_modules
    
    # Ensure path_id exists
    if not hasattr(learning_path, 'path_id') or not learning_path.path_id:
        learning_path.path_id = f"{learning_path.title.lower().replace(' ', '_')}_{learning_path.target_complexity.value}"
    
    logger.info(f"✅ Completed learning path with {len(completed_modules)} validated modules")
    return learning_path

def create_fallback_path(document_analyses: List[DocumentAnalysis], 
                        target_complexity: ComplexityLevel, 
                        repo_name: str) -> Tuple[List[LearningPath], List[str]]:
    """Create a simple fallback learning path"""
    logger.warning("Creating fallback learning path")
    
    # Simple fallback: group documents by type
    modules = []
    for i, doc in enumerate(document_analyses[:5]):  # Limit to first 5 docs
        module = LearningModule(
            module_id=f"module_{i+1:02d}",
            title=f"Module {i+1}: {doc.title}",
            description=doc.semantic_summary,
            documents=[doc.file_path],
            learning_objectives=doc.learning_objectives or [f"Understand {doc.title}"]
        )
        modules.append(module)
    
    fallback_path = LearningPath(
        path_id=f"{repo_name.lower()}_{target_complexity.value}_fallback",
        title=f"{repo_name} - {target_complexity.value.title()} Course",
        description=f"Basic {target_complexity.value} course for {repo_name}",
        target_complexity=target_complexity,
        modules=modules
    )
    
    return [fallback_path], ["Fallback path created due to debate system failure"]

# =============================================================================
# DSPy Signatures
# =============================================================================


class LearningPathProposer(dspy.Signature):
    """Propose a learning path structure with modules and document organization"""
    agent_instructions: str = dspy.InputField(desc="Instructions for the agent")
    documents_with_content: str = dspy.InputField(desc="Complete document information including content")
    target_complexity: str = dspy.InputField(desc="Target complexity level")
    overview_context: str = dspy.InputField(desc="Project overview for context")
    previous_critique: str = dspy.InputField(desc="Previous critique to address (empty for first round)")
    
    learning_path_proposal: LearningPath = dspy.OutputField(desc="JSON structured learning path with modules, documents, and learning objectives")
    reasoning: str = dspy.OutputField(desc="Explanation of the learning progression logic and how critique was addressed")

class LearningPathCritic(dspy.Signature):
    """Critique a learning path proposal and suggest specific improvements"""
    agent_instructions: str = dspy.InputField(desc="Instructions for the agent")
    learning_path_proposal: str = dspy.InputField(desc="Proposed learning path to critique")
    documents_with_content: str = dspy.InputField(desc="Complete document information for reference")
    target_complexity: str = dspy.InputField(desc="Target complexity level")
    overview_context: str = dspy.InputField(desc="Project overview for context")
    
    critique: str = dspy.OutputField(desc="Detailed critique with specific issues and improvement suggestions")
    severity: str = dspy.OutputField(desc="Overall assessment: 'major_issues', 'minor_issues', or 'acceptable'")

# =============================================================================
# Debate Learning Path Generator
# =============================================================================

class DebateLearningPathGenerator(dspy.Module):
    """Generate learning paths through multi-agent debate"""
    
    def __init__(self):
        super().__init__()
        self.proposer = dspy.ChainOfThought(LearningPathProposer)
        self.critic = dspy.ChainOfThought(LearningPathCritic)
    
    def _run_debate_round(self, round_num: int, documents_info: str, target_complexity: str,
                         overview_context: str, previous_critique: str, 
                         additional_instructions: str, progress_tracker: 'S3ProgressTracker' = None) -> Tuple[Optional[LearningPath], str]:
        """Run a single debate round"""
        logger.info(f"🔄 Debate Round {round_num}")
        
        # Proposer creates/refines learning path
        if progress_tracker:
            progress_tracker.update_debate_round(
                round_num, 
                "proposer", 
                f"Proposer creating learning path proposal..."
            )
        
        try:
            proposal_result = self.proposer(
                agent_instructions=f"{AGENT_INSTRUCTIONS}\n{additional_instructions}",
                documents_with_content=documents_info,
                target_complexity=target_complexity,
                overview_context=overview_context,
                previous_critique=previous_critique
            )
            
            current_proposal = proposal_result.learning_path_proposal
            reasoning = proposal_result.reasoning
            logger.info(f"📝 Proposer reasoning: {reasoning[:200]}...")
            
        except Exception as e:
            logger.error(f"❌ Proposer failed in round {round_num}: {e}")
            return None, f"Proposer failed: {e}"
        
        # Critic evaluates the proposal
        if progress_tracker:
            progress_tracker.update_debate_round(
                round_num, 
                "critic", 
                f"Critic evaluating learning path proposal..."
            )
        
        try:
            critique_result = self.critic(
                agent_instructions=f"{AGENT_INSTRUCTIONS}\n{additional_instructions}",
                learning_path_proposal=current_proposal.model_dump_json(),
                documents_with_content=documents_info,
                target_complexity=target_complexity,
                overview_context=overview_context
            )
            
            current_critique = critique_result.critique
            severity = critique_result.severity
            
            logger.info(f"🔍 Critic assessment: {severity}")
            logger.info(f"🔍 Critique: {current_critique[:200]}...")
            
            # Add to debate history
            if progress_tracker:
                progress_tracker.add_debate_history(
                    round_num, 
                    "completed", 
                    "completed",
                    severity,
                    current_critique,
                    reasoning
                )
                
                progress_tracker.update_debate_round(
                    round_num, 
                    "completed", 
                    f"Round {round_num} complete - {severity}"
                )
            
            return current_proposal, current_critique
            
        except Exception as e:
            logger.error(f"❌ Critic failed in round {round_num}: {e}")
            
            # Track failed critic
            if progress_tracker:
                progress_tracker.add_debate_history(
                    round_num, 
                    "completed", 
                    "failed",
                    "major_issues",
                    f"Critic failed: {e}",
                    reasoning if 'reasoning' in locals() else ""
                )
            
            return current_proposal, f"Critic failed: {e}"
    
    def generate_learning_path(self, 
                             document_analyses: List[DocumentAnalysis],
                             target_complexity: ComplexityLevel,
                             additional_instructions: str = "",
                             overview_context: str = "",
                             repo_name: str = "Documentation",
                             progress_tracker: 'S3ProgressTracker' = None) -> Tuple[List[LearningPath], List[str]]:
        """Generate learning path through iterative debate process"""
        
        logger.info(f"🎭 Starting debate-style learning path generation for {target_complexity.value}")
        
        # Prepare document information
        documents_info = prepare_document_info(document_analyses)
        overview_trimmed = get_n_words(overview_context, S3Config.MAX_OVERVIEW_WORDS)
        
        # Format additional instructions
        if additional_instructions:
            additional_instructions = f"Additional instructions: {additional_instructions}"
        else:
            additional_instructions = ""
        
        all_proposals = []
        all_critiques = []
        current_critique = ""
        
        # Iterative debate process
        for round_num in range(1, S3Config.MAX_DEBATES + 1):
            # Update progress for current round
            if progress_tracker:
                progress_tracker.update_debate_round(
                    round_num, 
                    "starting", 
                    f"Starting AI debate round {round_num} of {S3Config.MAX_DEBATES}"
                )
            
            proposal, critique = self._run_debate_round(
                round_num, documents_info, target_complexity.value,
                overview_trimmed, current_critique, additional_instructions,
                progress_tracker
            )
            
            if proposal is None:
                # Track failed round
                if progress_tracker:
                    progress_tracker.add_debate_history(
                        round_num, "failed", "not_reached", 
                        "major_issues", "Proposal generation failed", ""
                    )
                
                # If first round fails, create fallback
                if round_num == 1:
                    return create_fallback_path(document_analyses, target_complexity, repo_name)
                else:
                    break
            
            # Validate and complete the learning path structure
            proposal = validate_and_complete_learning_path(proposal, document_analyses)
            
            all_proposals.append(proposal)
            all_critiques.append(critique)
            current_critique = critique
            
            # Update proposals count
            if progress_tracker:
                total_modules = len(proposal.modules) if proposal else 0
                progress_tracker.update_proposals_count(len(all_proposals), total_modules)
            
            # Check if acceptable
            if "acceptable" in critique.lower():
                logger.info("✅ Learning path accepted by critic")
                if progress_tracker:
                    progress_tracker.update_debate_round(
                        round_num, 
                        "accepted", 
                        f"Proposal accepted by critic in round {round_num}"
                    )
                break
        
        return all_proposals, all_critiques

# =============================================================================
# Progress Tracker
# =============================================================================

class S3ProgressTracker:
    """Tracks and updates Stage 3 progress with detailed debate tracking"""
    
    def __init__(self, redis_client: redis.Redis, task_id: str, course_id: str = None):
        self.redis = redis_client
        self.task_id = task_id
        self.course_id = course_id
        self.progress_key = f"task:{task_id}:progress"
        self.detailed_progress_key = f"stage3_progress:{course_id}" if course_id else None
    
    def update_progress(self, stage: str, progress: int, message: str = ""):
        """Update basic progress in Redis"""
        try:
            progress_data = {
                'stage': stage,
                'progress': progress,
                'message': message,
                'timestamp': str(int(time.time()))
            }
            
            self.redis.hset(self.progress_key, mapping=progress_data)
            self.redis.expire(self.progress_key, 3600)  # Expire after 1 hour
            
            logger.info(f"Stage 3 Progress: {progress}% - {message}")
        except Exception as e:
            logger.error(f"Failed to update progress: {e}")
    
    def initialize_detailed_progress(self, total_documents: int, target_complexity: str):
        """Initialize detailed progress tracking"""
        if not self.detailed_progress_key:
            return
            
        try:
            from datetime import datetime
            detailed_data = {
                'stage': 'initializing',
                'current_round': 0,
                'max_rounds': 3,  # S3Config.MAX_DEBATES
                'current_step': 'preparation',
                'target_complexity': target_complexity,
                'total_documents': total_documents,
                'debate_history': [],
                'proposals_generated': 0,
                'total_modules_proposed': 0,
                'is_acceptable': False,
                'stage_description': 'Preparing documents for learning pathway generation',
                'started_at': datetime.now().isoformat(),
                'updated_at': datetime.now().isoformat()
            }
            
            self.redis.set(self.detailed_progress_key, json.dumps(detailed_data), ex=3600)
            logger.info(f"Initialized Stage 3 detailed progress for {total_documents} documents")
        except Exception as e:
            logger.error(f"Failed to initialize detailed progress: {e}")
    
    def update_debate_round(self, round_num: int, step: str, description: str = ""):
        """Update current debate round progress"""
        if not self.detailed_progress_key:
            return
            
        try:
            from datetime import datetime
            
            # Get current progress
            current_data = self.redis.get(self.detailed_progress_key)
            if current_data:
                detailed_data = json.loads(current_data)
            else:
                detailed_data = {}
            
            # Update round information
            detailed_data.update({
                'stage': f'debate_round_{round_num}',
                'current_round': round_num,
                'current_step': step,
                'stage_description': description or f'AI Debate Round {round_num}: {step}',
                'updated_at': datetime.now().isoformat()
            })
            
            self.redis.set(self.detailed_progress_key, json.dumps(detailed_data), ex=3600)
            logger.info(f"Stage 3 Round {round_num}: {step} - {description}")
        except Exception as e:
            logger.error(f"Failed to update debate round: {e}")
    
    def add_debate_history(self, round_num: int, proposal_status: str, critique_status: str, 
                          severity: str = "", critique_summary: str = "", reasoning: str = ""):
        """Add debate round to history"""
        if not self.detailed_progress_key:
            return
            
        try:
            from datetime import datetime
            
            # Get current progress
            current_data = self.redis.get(self.detailed_progress_key)
            if current_data:
                detailed_data = json.loads(current_data)
            else:
                detailed_data = {'debate_history': []}
            
            # Add new debate entry
            debate_entry = {
                'round': round_num,
                'proposal_status': proposal_status,
                'critique_status': critique_status,
                'severity': severity,
                'critique_summary': critique_summary[:200] + "..." if len(critique_summary) > 200 else critique_summary,
                'reasoning': reasoning[:200] + "..." if len(reasoning) > 200 else reasoning,
                'timestamp': datetime.now().isoformat()
            }
            
            if 'debate_history' not in detailed_data:
                detailed_data['debate_history'] = []
            
            detailed_data['debate_history'].append(debate_entry)
            detailed_data['updated_at'] = datetime.now().isoformat()
            
            # Update acceptance status
            if severity and 'acceptable' in severity.lower():
                detailed_data['is_acceptable'] = True
            
            self.redis.set(self.detailed_progress_key, json.dumps(detailed_data), ex=3600)
            logger.info(f"Added debate history for round {round_num}: {severity}")
        except Exception as e:
            logger.error(f"Failed to add debate history: {e}")
    
    def update_proposals_count(self, proposals_count: int, total_modules: int):
        """Update proposal generation counts"""
        if not self.detailed_progress_key:
            return
            
        try:
            from datetime import datetime
            
            # Get current progress
            current_data = self.redis.get(self.detailed_progress_key)
            if current_data:
                detailed_data = json.loads(current_data)
            else:
                detailed_data = {}
            
            detailed_data.update({
                'proposals_generated': proposals_count,
                'total_modules_proposed': total_modules,
                'updated_at': datetime.now().isoformat()
            })
            
            self.redis.set(self.detailed_progress_key, json.dumps(detailed_data), ex=3600)
        except Exception as e:
            logger.error(f"Failed to update proposals count: {e}")
    
    def finalize_progress(self, final_paths_count: int, final_modules_count: int):
        """Mark progress as completed"""
        if not self.detailed_progress_key:
            return
            
        try:
            from datetime import datetime
            
            # Get current progress
            current_data = self.redis.get(self.detailed_progress_key)
            if current_data:
                detailed_data = json.loads(current_data)
            else:
                detailed_data = {}
            
            detailed_data.update({
                'stage': 'completed',
                'current_step': 'finalized',
                'stage_description': f'Pathway generation complete: {final_paths_count} paths, {final_modules_count} modules',
                'final_paths_count': final_paths_count,
                'final_modules_count': final_modules_count,
                'completed_at': datetime.now().isoformat(),
                'updated_at': datetime.now().isoformat()
            })
            
            self.redis.set(self.detailed_progress_key, json.dumps(detailed_data), ex=300)  # Keep for 5 minutes
            logger.info(f"Stage 3 completed: {final_paths_count} paths, {final_modules_count} modules")
        except Exception as e:
            logger.error(f"Failed to finalize progress: {e}")

# =============================================================================
# Main Stage 3 Processor
# =============================================================================

def process_stage3(stage2_result: Stage2Result, target_complexity: ComplexityLevel = ComplexityLevel.INTERMEDIATE,
                  additional_instructions: str = "", task_id: str = None, 
                  redis_client: redis.Redis = None, course_id: str = None) -> Stage3Result:
    """
    Process Stage 3: Learning pathway generation
    
    Args:
        stage2_result: Result from Stage 2 with document analyses
        target_complexity: Target complexity level for the learning path
        additional_instructions: Additional instructions for path generation
        task_id: Task ID for progress tracking
        redis_client: Redis client for progress updates
    
    Returns:
        Stage3Result with learning paths and debate history
    """
    start_time = time.time()
    
    # Initialize progress tracker
    progress_tracker = None
    if task_id and redis_client:
        progress_tracker = S3ProgressTracker(redis_client, task_id, course_id)
        progress_tracker.update_progress("stage3", 0, "Starting learning pathway generation")
        
        # Initialize detailed progress tracking
        if course_id:
            progress_tracker.initialize_detailed_progress(
                len(stage2_result.document_analyses), 
                target_complexity.value
            )
    
    try:
        # Initialize learning path generator
        generator = DebateLearningPathGenerator()
        
        if progress_tracker:
            progress_tracker.update_progress("stage3", 10, "Initializing learning path generator")
        
        # Generate learning paths through debate
        all_proposals, all_critiques = generator.generate_learning_path(
            document_analyses=stage2_result.document_analyses,
            target_complexity=target_complexity,
            additional_instructions=additional_instructions,
            overview_context=getattr(stage2_result, 'overview_context', ''),
            repo_name=getattr(stage2_result, 'repo_name', 'Documentation'),
            progress_tracker=progress_tracker
        )
        
        # Use the last (best) proposal as the final learning paths
        learning_paths = all_proposals[-1:] if all_proposals else []
        
        # Format debate history for storage
        debate_history = []
        for i, (proposal, critique) in enumerate(zip(all_proposals, all_critiques)):
            debate_history.append(f"Round {i+1}: Proposal generated | Critique: {critique[:200]}...")
        
        if not learning_paths:
            # Fallback if no proposals generated
            learning_paths, fallback_history = create_fallback_path(
                stage2_result.document_analyses, target_complexity, 
                getattr(stage2_result, 'repo_name', 'Documentation')
            )
            debate_history.extend(fallback_history)
        
        if progress_tracker:
            progress_tracker.update_progress("stage3", 80, f"Generated {len(learning_paths)} learning paths")
        
        # Create result
        result = Stage3Result(
            stage2_result=stage2_result,
            learning_paths=learning_paths,
            target_complexity=target_complexity,
            debate_history=debate_history,
            additional_instructions=additional_instructions,
            total_modules=sum(len(path.modules) for path in learning_paths),
            metadata={
                'processing_time': time.time() - start_time,
                'stage': 'stage3',
                'debate_rounds': len(debate_history),
                'path_generation_version': '1.0'
            }
        )
        
        if progress_tracker:
            total_modules = sum(len(path.modules) for path in learning_paths)
            progress_tracker.update_progress("stage3", 100, f"Stage 3 complete: {len(learning_paths)} paths, {total_modules} modules")
            progress_tracker.finalize_progress(len(learning_paths), total_modules)
        
        logger.info(f"Stage 3 completed: {len(learning_paths)} learning paths generated with {len(debate_history)} debate rounds")
        return result
        
    except Exception as e:
        logger.error(f"Stage 3 failed: {e}")
        if progress_tracker:
            progress_tracker.update_progress("stage3", -1, f"Stage 3 failed: {str(e)}")
        raise e 